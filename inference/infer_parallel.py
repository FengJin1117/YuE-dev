# åˆ†é…GPU
# è¾“å‡ºï¼šç»“æœéŸ³é¢‘ï¼ˆäººå£°+æ··å£°ï¼‰ã€‚output/
# 1_vocal.wav
# 1_mixed.mp3
# ä¸€ä¸ªjsonï¼Œæ‹†åˆ†ï¼ˆåªè¦éŸ³é¢‘ï¼‰

import os
import json
import argparse
import subprocess
import tempfile
import time
from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, \
    nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount, nvmlShutdown

def get_available_gpus(min_free_memory_gb=8):
    nvmlInit()
    device_count = nvmlDeviceGetCount()
    available = []

    for i in range(device_count):
        handle = nvmlDeviceGetHandleByIndex(i)
        mem_info = nvmlDeviceGetMemoryInfo(handle)
        free_gb = mem_info.free / 1024 / 1024 / 1024
        if free_gb >= min_free_memory_gb:
            available.append(i)

    nvmlShutdown()
    return available

def split_json(json_path, num_splits):
    with open(json_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    total = len(lines)
    per_gpu = (total + num_splits - 1) // num_splits  # å‘ä¸Šå–æ•´

    split_paths = []
    for i in range(num_splits):
        part = lines[i * per_gpu: (i + 1) * per_gpu]
        if not part:
            break
        tmp_file = tempfile.NamedTemporaryFile(mode="w+", delete=False, suffix=".json", encoding="utf-8")
        tmp_file.writelines(part)
        tmp_file.close()
        split_paths.append(tmp_file.name)

    return split_paths

def launch_processes(split_paths, gpu_indices, output_dir):
    processes = []

    for i, (json_file, gpu_id) in enumerate(zip(split_paths, gpu_indices)):
        cmd = [
            "python", "infer_json.py",
            "--json_path", json_file,
            "--output_dir", output_dir,
            "--cuda_idx", str(gpu_id)
        ]
        print(f"ğŸš€ å¯åŠ¨ GPU{gpu_id} ä»»åŠ¡ï¼Œè¾“å…¥ï¼š{json_file}")
        p = subprocess.Popen(cmd)
        processes.append(p)

    try:
        for p in processes:
            p.wait()
    except KeyboardInterrupt:
        print("âš ï¸ æ£€æµ‹åˆ°ä¸­æ–­ï¼Œç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹...")
        for p in processes:
            p.terminate()
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for path in split_paths:
            os.remove(path)
        print("ğŸ§¹ æ‰€æœ‰ä¸´æ—¶ JSON å­æ–‡ä»¶å·²æ¸…é™¤")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--json_path", type=str, required=True, help="æ€» JSON è¾“å…¥æ–‡ä»¶")
    parser.add_argument("--output_dir", type=str, default="./output", help="è¾“å‡ºè·¯å¾„")
    parser.add_argument("--min_free_mem", type=int, default=8, help="å¯ç”¨GPUæ‰€éœ€æœ€å°ç©ºé—²æ˜¾å­˜(GB)")
    args = parser.parse_args()

    # æ£€æµ‹å¯ç”¨ GPU
    gpus = get_available_gpus(min_free_memory_gb=args.min_free_mem)
    if not gpus:
        print("âŒ æ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„GPUï¼ˆç©ºé—²æ˜¾å­˜ â‰¥ {}GBï¼‰".format(args.min_free_mem))
        exit(1)

    print(f"âœ… æ£€æµ‹åˆ°å¯ç”¨ GPU: {gpus}")

    # æ‹†åˆ† JSON
    split_paths = split_json(args.json_path, len(gpus))

    # å¯åŠ¨å¹¶è¡Œä»»åŠ¡
    launch_processes(split_paths, gpus, args.output_dir)
